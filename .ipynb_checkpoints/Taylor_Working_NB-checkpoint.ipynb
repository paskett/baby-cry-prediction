{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft, ifft, dct, idct\n",
    "from scipy.signal import fftconvolve\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.dpi\"] = 400             # Fix plot quality.\n",
    "plt.rcParams[\"figure.figsize\"] = (12,3)      # Change plot size / aspect (you may adjust this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory='raw_data'):\n",
    "    \"\"\"\n",
    "    Function to load sound data from the donateacry dataset.\n",
    "    Also normalizes each to have the same length.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str\n",
    "                directory to search for data\n",
    "    scale     : bool\n",
    "                indicates whether to scale data or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    wavforms : ndarray\n",
    "               array of data points (each waveform)\n",
    "    labels : ndarray\n",
    "             array of labels corresponding to each waveform\n",
    "    \"\"\"\n",
    "    subdirs = os.listdir(directory)\n",
    "    wavforms = []\n",
    "    labels = []\n",
    "    for dirc in subdirs:\n",
    "        filenames = os.listdir(directory+'/'+dirc)\n",
    "        for filename in filenames:\n",
    "            # Get wavform from each file \n",
    "            wav = wavfile.read(directory+'/'+dirc+'/'+filename)[1]\n",
    "                \n",
    "            # Store wavform and appropriate label\n",
    "            wavforms.append(wav)\n",
    "            labels.append(dirc)\n",
    "    \n",
    "    # Find the minimum wavform length.\n",
    "    lens = set()\n",
    "    for d in wavforms:\n",
    "        lens.add(len(d))\n",
    "    min_len = min(lens)\n",
    "    \n",
    "    # Cut the end off each wavform so they're the same lengths.\n",
    "    for i,wav in enumerate(wavforms):\n",
    "        wavforms[i] = wav[:min_len]\n",
    "\n",
    "    return np.array(wavforms), np.array(labels)\n",
    "\n",
    "def duplicate_data(data, labels, alpha=0.3333):\n",
    "    \"\"\"\n",
    "    Duplicates data and adds random noise to the duplicates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data (ndarray): array of waveform values.\n",
    "    labels (ndarray): array of labels for each row of data.\n",
    "    alpha (float): a parameter that changes how large the noise may be for \n",
    "            all waveforms relative to each of their sample values.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    new_data (ndarray): all the same rows as data with noisy rows as well\n",
    "    new_labels (ndarray): the labels corresponding to the rows of new_data\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    for wav, label in zip(data, labels):\n",
    "        # Sample noise from the normal distribution.\n",
    "        noise = np.array([np.random.normal(scale=max(abs(x)*alpha, 0)) for x in wav])\n",
    "        \n",
    "        new_wav = wav.astype(np.int64) + noise.astype(np.int64)\n",
    "        \n",
    "        # Rescale the new_wav to make sure no parts go above 32767.\n",
    "        new_wav = np.array(32767*new_wav/np.max(np.abs(new_wav))).astype(np.int16)\n",
    "        \n",
    "        new_data.append(new_wav)\n",
    "        new_labels.append(label)\n",
    "    \n",
    "    # Concatenate the old and new data/labels.\n",
    "    new_data = np.vstack([data, np.array(new_data)])\n",
    "    new_labels = np.hstack([labels, np.array(new_labels)])\n",
    "    \n",
    "    return new_data, new_labels\n",
    "\n",
    "\n",
    "def cut_data(data, labels, n):\n",
    "    \"\"\"\n",
    "    Takes data and cuts each sample into parts of specified length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data   : ndarray\n",
    "             array of waveform values of constant length\n",
    "    labels : ndarray\n",
    "             array of labels for each row of data\n",
    "    n.     : int\n",
    "             desired length of new samples\n",
    "             \n",
    "    Returns\n",
    "    -------\n",
    "    new_data   : ndarray\n",
    "                 array of new cut samples\n",
    "    new_labels : ndarray\n",
    "                 array of corresponding labels\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    # Get number of possible subsamples from current samples\n",
    "    subs = length//n\n",
    "\n",
    "    # Cut each sample\n",
    "    for i, wav in enumerate(data):\n",
    "        # Get as many new samples from old sample as possible\n",
    "        for x in range(subs):\n",
    "            # Extract subsamples of length n\n",
    "            new_data.append(wav[x*n:(x+1)*n])\n",
    "            # Store corresponding label\n",
    "            new_labels.append(labels[i])\n",
    "            \n",
    "    return new_data, new_labels\n",
    "\n",
    "\n",
    "def get_fft(data, rate=8000):\n",
    "    \"\"\"\n",
    "    Function to transform wavelength data into frequency data using the FFT\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray\n",
    "           Array where each row is the wavelength samples of a single cry instance\n",
    "           \n",
    "    Returns\n",
    "    -------\n",
    "    freqs       : ndarray\n",
    "                  Array whose rows are the sampled frequencies\n",
    "    freq_domain : domain of frequency values\n",
    "    \"\"\"\n",
    "    freqs = []\n",
    "    freq_domain = np.arange(0, len(data[0])) * rate / len(data[0])\n",
    "    freq_domain = freq_domain[:len(freq_domain)//2]\n",
    "    \n",
    "    for i, wav in enumerate(data):\n",
    "        # Get frequencies using Fourier Transform\n",
    "        f = np.abs(fft(wav))[:len(freq_domain)]\n",
    "        # Get real part of frequencies, normalize, and sample every 100\n",
    "        tmp = (np.real(f) / np.real(max(f)))[::100]\n",
    "        freqs.append(list(tmp))\n",
    "    \n",
    "    return np.array(freqs), freq_domain[::100]\n",
    "\n",
    "def labels_to_integers(labels):\n",
    "    \"\"\"\n",
    "    Convert the array of all labels (strings) to integer values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels (ndarray): array of strings containing the label name for\n",
    "        each data point\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_labels (ndarray): array where labels are replaced with ints\n",
    "    mapping (dict): a mapping from int -> string showing which integer\n",
    "        corresponds to which label\n",
    "    \"\"\"\n",
    "    new_labels = np.zeros(labels.shape, dtype=int)\n",
    "    mapping = {}\n",
    "    \n",
    "    for idx, lab in enumerate(np.unique(labels)):\n",
    "        new_labels[labels==lab] = idx\n",
    "        mapping[idx] = lab\n",
    "    \n",
    "    return new_labels, mapping\n",
    "    \n",
    "def cut_data(data, labels, n):\n",
    "    \"\"\"\n",
    "    Takes data and cuts each sample into parts of specified length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data   : ndarray\n",
    "             array of waveform values of constant length\n",
    "    labels : ndarray\n",
    "             array of labels for each row of data\n",
    "    n.     : int\n",
    "             desired length of new samples\n",
    "             \n",
    "    Returns\n",
    "    -------\n",
    "    new_data   : ndarray\n",
    "                 array of new cut samples\n",
    "    new_labels : ndarray\n",
    "                 array of corresponding labels\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    # Get number of possible subsamples from current samples\n",
    "    subs = data.shape[1]//n\n",
    "\n",
    "    # Cut each sample\n",
    "    for i, wav in enumerate(data):\n",
    "        # Get as many new samples from old sample as possible\n",
    "        for x in range(subs):\n",
    "            # Extract subsamples of length n\n",
    "            new_data.append(wav[x*n:(x+1)*n])\n",
    "            # Store corresponding label\n",
    "            new_labels.append(labels[i])\n",
    "            \n",
    "    return np.array(new_data), np.array(new_labels)\n",
    "\n",
    "def data_to_df(data, labels, freqs):\n",
    "    \"\"\"\n",
    "    Function to convert numpy array of data to a pandas DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data  : ndarray\n",
    "            Array whose rows are of the form [[frequencies], 'label']\n",
    "    label : list or ndarray of shape (n,)\n",
    "            list of labels corresponding to each row of data\n",
    "    freqs : list or ndarray of shape (n,)\n",
    "            Frequency domain of the passed data (used to make column names)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "         DataFrame where each row is a cry instance and each column is a frequency\n",
    "         with a final 'label' column\n",
    "    \"\"\"\n",
    "    # Data to df\n",
    "    df = pd.DataFrame(data,columns=freqs)\n",
    "    # Labels column\n",
    "    df['labels'] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data.\n",
    "X, y = load_data()\n",
    "\n",
    "# Duplicate everything except the hungry data (of which there is already a lot).\n",
    "X_dup, y_dup = duplicate_data(X[y != 'hungry'], y[y != 'hungry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the data together.\n",
    "X = np.vstack([X_dup, X[y == 'hungry'][::3]])\n",
    "y = np.hstack([y_dup, y[y == 'hungry'][::3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make y be integer-valued.\n",
    "y, mapping = labels_to_integers(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data in frequency space\n",
    "Xf, freqs = get_fft(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(Xf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try some ML methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_train, Xf_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xf, X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLSf = LinearRegression().fit(Xf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct (rounded to nearest class): 0.2391\n"
     ]
    }
   ],
   "source": [
    "pct_correct = np.mean(np.round(OLSf.predict(Xf_test)) != y_test)\n",
    "print('Percent correct (rounded to nearest class):', round(1 - pct_fail, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2391304347826087"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.round(OLSf.predict(Xf_test)) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 value: -6.185488616398643\n"
     ]
    }
   ],
   "source": [
    "print('R^2 value:', OLSf.score(Xf_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS = LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct (rounded to nearest class): 0.2391\n"
     ]
    }
   ],
   "source": [
    "pct_correct = np.mean(np.round(OLS.predict(X_test)) != y_test)\n",
    "print('Percent correct (rounded to nearest class):', round(1 - pct_fail, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32608695652173914"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.round(OLS.predict(X_test)) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 value: -1.4382597217286501\n"
     ]
    }
   ],
   "source": [
    "print('R^2 value:', OLS.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/tay/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "qdaf = QuadraticDiscriminantAnalysis().fit(Xf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34782608695652173"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(qdaf.predict(Xf_test) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/tay/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2717391304347826"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(qda.predict(X_test) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/tay/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "ldaf = LinearDiscriminantAnalysis().fit(Xf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44565217391304346"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ldaf.predict(Xf_test) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/tay/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7065217391304348"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lda.predict(X_test) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5).fit(Xf)\n",
    "km.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=5).fit(Xf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 1, 4, 1, 1, 1, 0, 4, 3, 1, 2, 4, 2, 0, 1, 0, 0, 4, 4, 2, 2,\n",
       "       1, 3, 4, 4, 3, 1, 3, 0, 1, 1, 4, 1, 0, 3, 4, 1, 1, 4, 3, 4, 4, 1,\n",
       "       3, 1, 1, 0, 4, 0, 1, 1, 2, 1, 4, 4, 1, 3, 4, 1, 4, 4, 2, 1, 3, 2,\n",
       "       1, 4, 3, 4, 1, 1, 1, 2, 2, 0, 2, 2, 3, 3, 3, 3, 4, 1, 1, 1, 4, 3,\n",
       "       4, 4, 2, 1])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.predict(Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 4., 3., 4., 3., 3., 2., 3., 3., 4., 0., 3., 3., 2., 3., 2., 3.,\n",
       "       4., 3., 3., 1., 4., 3., 3., 3., 3., 0., 2., 0., 1., 2., 3., 2., 3.,\n",
       "       3., 0., 3., 3., 0., 4., 1., 3., 4., 2., 1., 3., 2., 0., 3., 3., 0.,\n",
       "       3., 3., 0., 3., 0., 3., 1., 2., 0., 3., 3., 2., 4., 2., 3., 3., 4.,\n",
       "       4., 3., 2., 4., 3., 0., 2., 3., 3., 2., 1., 2., 3., 4., 3., 3., 2.,\n",
       "       3., 4., 4., 3., 3., 3., 2.])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA STUFF -- PLAYING AROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundWave(object):\n",
    "    \"\"\"A class for working with digital audio signals.\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, rate, samples):\n",
    "        \"\"\"Set the SoundWave class attributes.\n",
    "\n",
    "        Parameters:\n",
    "            rate (int): The sample rate of the sound.\n",
    "            samples ((n,) ndarray): NumPy array of samples.\n",
    "        \"\"\"\n",
    "        # Set the attributes\n",
    "        self.rate = rate\n",
    "        self.samples = samples\n",
    "        self.num_samples = samples.size\n",
    "\n",
    "\n",
    "    def plot(self, useDFT=False):\n",
    "        \"\"\"Plot the graph of the sound wave (time versus amplitude).\"\"\"\n",
    "        plt.figure()\n",
    "        if useDFT:\n",
    "            plt.subplot(122)\n",
    "            plt.title(\"Fourier Transform\")\n",
    "            plt.xlabel(\"Frequency (Hz)\")\n",
    "            plt.ylabel(\"Magnitude\")\n",
    "            # Correctly set the x axis to be in terms of frequency\n",
    "            x = np.arange(self.num_samples)*self.rate/self.num_samples\n",
    "            y = np.abs(fft(self.samples))\n",
    "            x_end = self.num_samples*self.rate/self.num_samples/2\n",
    "            #plt.xlim(-.02*x_end,x_end)\n",
    "            plt.ylim(0,1.075*np.max(y))\n",
    "            plt.plot(x,y)\n",
    "            plt.subplot(121)\n",
    "        \n",
    "        # Set the y axis limits\n",
    "        plt.ylim(-32768, 32767)\n",
    "        plt.title(\"Sound Wave\")\n",
    "        # Correctly label the x axis in terms of seconds\n",
    "        x = np.linspace(0,self.num_samples/self.rate,self.num_samples)\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Samples\")\n",
    "        plt.plot(x,self.samples)\n",
    "\n",
    "\n",
    "    def export(self, filename, force=False):\n",
    "        \"\"\"Generate a wav file from the sample rate and samples. \n",
    "        If the array of samples is not of type np.int16, scale it before exporting.\n",
    "\n",
    "        Parameters:\n",
    "            filename (str): The name of the wav file to export the sound to.\n",
    "        \"\"\"\n",
    "        # Note: we convert to int64 so that we can multiply by \n",
    "        #  32767, then we convert the result back to int16\n",
    "        if force:\n",
    "            samples = np.array(self.samples,dtype=np.int64)\n",
    "            samples = np.array(32767*samples/np.max(np.abs(samples)),\n",
    "                               dtype=np.int16)\n",
    "        elif type(self.samples) is not np.int16:\n",
    "            samples = np.array(32767*samples/np.max(np.abs(samples)),\n",
    "                               dtype=np.int16)\n",
    "        else:\n",
    "            samples = self.samples\n",
    "\n",
    "        # Write the samples to a file\n",
    "        wavfile.write(filename, self.rate, samples)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the sound file in seconds.\"\"\"\n",
    "        return int(round(self.num_samples/self.rate))\n",
    "\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        \"\"\"Combine the samples from two SoundWave objects.\n",
    "\n",
    "        Parameters:\n",
    "            other (SoundWave): An object containing the samples to add\n",
    "                to the samples contained in this object.\n",
    "        \n",
    "        Returns:\n",
    "            (SoundWave): A new SoundWave instance with the combined samples.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if the two sample arrays are not the same length.\n",
    "        \"\"\"\n",
    "        # Make sure they are the same length\n",
    "        if other.num_samples != self.num_samples:\n",
    "            raise ValueError(\"The two sample sounds are not the same length.\")\n",
    "        \n",
    "        # Get the element-wise sum of the two samples.\n",
    "        sample1 = np.array(other.samples,dtype=np.int32)\n",
    "        sample2 = np.array(self.samples,dtype=np.int32)\n",
    "        summed_wave = sample1 + sample2\n",
    "        # Scale the sample if necessary\n",
    "        if np.max(np.abs(summed_wave)) > 32767:\n",
    "            summed_wave = np.array(summed_wave*32767\n",
    "                    /np.max(np.abs(summed_wave)),dtype=np.int16)\n",
    "            \n",
    "        return SoundWave(self.rate, summed_wave)\n",
    "        \n",
    "\n",
    "    # Problem 1.4\n",
    "    def __rshift__(self, other):\n",
    "        \"\"\"Concatentate the samples from two SoundWave objects.\n",
    "\n",
    "        Parameters:\n",
    "            other (SoundWave): An object containing the samples to concatenate\n",
    "                to the samples contained in this object.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if the two sample rates are not equal.\n",
    "        \"\"\"\n",
    "        # Error checking\n",
    "        if other.rate != self.rate:\n",
    "            raise ValueError(\"The two samples' rates are not equal.\")\n",
    "        \n",
    "        return SoundWave(self.rate, np.concatenate((self.samples,other.samples)))\n",
    "                                   \n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"Convolve the samples from two SoundWave objects using circular convolution.\n",
    "        \n",
    "        Parameters:\n",
    "            other (SoundWave): An object containing the samples to convolve\n",
    "                with the samples contained in this object.\n",
    "        \n",
    "        Returns:\n",
    "            (SoundWave): A new SoundWave instance with the convolved samples.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if the two sample rates are not equal.\n",
    "        \"\"\"\n",
    "        if self.rate != other.rate:\n",
    "            raise ValueError(\"The sample rates are not equal.\")\n",
    "        \n",
    "        f = self.samples\n",
    "        g = other.samples\n",
    "        if len(f) < len(g):\n",
    "            f = np.concatenate([f,np.zeros(len(g)-len(f))])\n",
    "        if len(g) < len(f):\n",
    "            g = np.concatenate([g,np.zeros(len(f)-len(g))])\n",
    "            \n",
    "        f_conv_g = ifft(fft(f)*fft(g)).real\n",
    "        return SoundWave(self.rate, f_conv_g)\n",
    "\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        \"\"\"Convolve the samples from two SoundWave objects using linear convolution.\n",
    "        \n",
    "        Parameters:\n",
    "            other (SoundWave): An object containing the samples to convolve\n",
    "                with the samples contained in this object.\n",
    "        \n",
    "        Returns:\n",
    "            (SoundWave): A new SoundWave instance with the convolved samples.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if the two sample rates are not equal.\n",
    "        \"\"\"\n",
    "        if self.rate != other.rate:\n",
    "            raise ValueError(\"The sample rates are not equal.\")\n",
    "            \n",
    "        n,m = self.num_samples, other.num_samples\n",
    "        \n",
    "        # Find the smallest 2**a such that 2**a >= n + m - 1\n",
    "        to_compare = n + m - 1\n",
    "        a = 0\n",
    "        while 2**a < to_compare:\n",
    "            a += 1\n",
    "        \n",
    "        # Append zeros to f,g so that both are length 2**a\n",
    "        f, g = self.samples, other.samples\n",
    "        f = np.concatenate([f,np.zeros(2**a - n)])\n",
    "        g = np.concatenate([g,np.zeros(2**a - m)])\n",
    "        \n",
    "        out = ifft(fft(f)*fft(g))[:(n+m-1)].real\n",
    "        return SoundWave(self.rate, out)\n",
    "\n",
    "    \n",
    "    def clean(self, low_freq, high_freq):\n",
    "        \"\"\"Remove a range of frequencies from the samples using the DFT. \n",
    "\n",
    "        Parameters:\n",
    "            low_freq (float): Lower bound of the frequency range to zero out.\n",
    "            high_freq (float): Higher boound of the frequency range to zero out.\n",
    "        \"\"\"\n",
    "        \n",
    "        a, b = ( int(low_freq/self.rate*self.num_samples), \n",
    "                 int(high_freq/self.rate*self.num_samples) )\n",
    "        \n",
    "        # Get the frequencies\n",
    "        freq = fft(self.samples)\n",
    "        \n",
    "        # zero them out between the low and high frequency\n",
    "        freq[a:b] = 0 \n",
    "        freq[(freq.size-b):(freq.size-a)] = 0\n",
    "        \n",
    "        # Convert the frequencies back to the sound wave\n",
    "        self.samples = ifft(freq).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the test files I can mess around with.\n",
    "file_ti1 = 'raw_data/tired/03ADDCFB-354E-416D-BF32-260CF47F7060-1433658024-1.1-f-04-ti.wav'\n",
    "file_ti2 = 'raw_data/tired/06c4cfa2-7fa6-4fda-91a1-ea186a4acc64-1430029221058-1.7-f-26-ti.wav'\n",
    "file_hu1 = 'raw_data/hungry/02c3b725-26e4-4a2c-9336-04ddc58836d9-1430726196216-1.7-m-04-hu.wav'\n",
    "file_hu2 = 'raw_data/hungry/02ead89b-aa02-453e-8b83-6ebde9fe7551-1430233132879-1.7-m-26-hu.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW = SoundWave(*wavfile.read(file_ti2))\n",
    "SW.plot(useDFT=True)\n",
    "IPython.display.Audio(filename=file_ti2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW = SoundWave(*wavfile.read(file_hu1))\n",
    "SW.plot(useDFT=True)\n",
    "IPython.display.Audio(filename=file_hu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW2 = SoundWave(*wavfile.read(file_hu2))\n",
    "SW2.plot(useDFT=True)\n",
    "IPython.display.Audio(filename=file_hu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW = SoundWave(*wavfile.read(file_ti1))\n",
    "SW.plot(useDFT=True)\n",
    "IPython.display.Audio(filename=file_ti1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bare_y = y[::10]\n",
    "ifftbare_y = ifft(bare_y).real\n",
    "new_samples = 32767*ifftbare_y/np.max(np.abs(ifftbare_y))\n",
    "bare_SW = SoundWave(SW.rate//10, new_samples)\n",
    "bare_SW.plot(useDFT=True)\n",
    "bare_SW.export('reduced_sound.wav', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(filename='reduced_sound.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(SW.num_samples)*SW.rate/SW.num_samples\n",
    "y = np.abs(fft(SW.samples))\n",
    "plt.figure()\n",
    "plt.plot(x[:len(x)//2], y[:len(x)//2])\n",
    "plt.title(f'Using {len(x)//2} frequency measurements')\n",
    "plt.figure()\n",
    "plt.plot(x[:len(x)//2:10], y[:len(x)//2:10])\n",
    "plt.title(f'Using {len(x[:len(x)//2:10])} frequency measurements')\n",
    "plt.figure()\n",
    "plt.plot(x[:len(x)//2:100], y[:len(x)//2:100])\n",
    "plt.title(f'Using {len(x[:len(x)//2:100])} frequency measurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section to get all the data files.\n",
    "all_data = []\n",
    "for folder in ['belly_pain', 'burping', 'discomfort', 'hungry', 'tired']:\n",
    "    all_data.append('raw_data/'+folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup, lab = duplicate_data(data[:2], labels[:2])\n",
    "dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(dup[0][0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dup[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "lens = set()\n",
    "for d, _ in data:\n",
    "    X.append(d)\n",
    "X = np.array(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
